# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XCOYBxnyT24HgoE0hqLth93Z5wBH5TWa
"""

from google.colab import drive
drive.mount("/content/drive")

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE

transportation = pd.read_csv("/content/drive/My Drive/transportation.csv")

transportation.head()

transportation.info()

transportation.isnull().sum()

sns.countplot(data = transportation, x = "has_delay")

import seaborn as sns
import matplotlib.pyplot as plt

# Scatter plot with delay coloring
sns.scatterplot(data=transportation, x='scheduled_time', y='expected_time', hue='has_delay')
plt.title('Scheduled Time vs Expected Time (colored by Delay)')
plt.show()

# Analysing relationship of Gender with heart attack
sns.countplot(data  = transportation, x = 'expected_time', hue="has_delay")

le_date = LabelEncoder()
transportation["date"] = le_date.fit_transform(transportation['date'])

le_date = LabelEncoder()
transportation["Hbf"] = le_date.fit_transform(transportation['Hbf'])

le_date = LabelEncoder()
transportation["Hbf"] = le_date.fit_transform(transportation['Hbf'])

le_date = LabelEncoder()
transportation["scheduled_time"] = le_date.fit_transform(transportation['scheduled_time'])

le_date = LabelEncoder()
transportation["expected_time"] = le_date.fit_transform(transportation['expected_time'])

le_date = LabelEncoder()
transportation["route"] = le_date.fit_transform(transportation['route'])

le_date = LabelEncoder()
transportation["platform"] = le_date.fit_transform(transportation['platform'])

le_date = LabelEncoder()
transportation["train_model"] = le_date.fit_transform(transportation['train_model'])

le_date = LabelEncoder()
transportation["real_time_due_to_delay"] = le_date.fit_transform(transportation['real_time_due_to_delay'])

# Initialize the LabelEncoder
le = LabelEncoder()
# Apply LabelEncoder to multiple columns
transportation["has_delay"] = le.fit_transform(transportation["has_delay"])
# Visualise the heatmap
corr =transportation.corr()
plt.figure(figsize= (10, 8))
sns.heatmap(corr, annot= True, cmap='GnBu')
plt.show()

# Set the figure size
plt.figure(figsize=(15, 5))
sns.boxplot(data=transportation.select_dtypes(include='number'))
plt.title("Detect the Outlier values")
plt.xticks(rotation=45)  # Rotate x-axis labels
plt.show()

import warnings
from scipy import stats
# Suppress specific scipy/numpy warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)
def best_fit_distribution(data, bins=30):
    distributions = [stats.norm, stats.expon, stats.lognorm, stats.gamma, stats.beta]
    best_dist = None
    best_sse = np.inf

    for dist in distributions:
        try:
            params = dist.fit(data)
            x = np.linspace(min(data), max(data), bins)
            pdf = dist.pdf(x, *params[:-2], loc=params[-2], scale=params[-1])
            hist, _ = np.histogram(data, bins=bins, density=True)
            sse = np.sum((hist - pdf[:bins])**2)
            if sse < best_sse:
                best_sse = sse
                best_dist = dist
        except Exception:
            continue
    return best_dist.name if best_dist else "Unknown"

#Plotting
numeric_cols = transportation.select_dtypes(include='number').columns
n_cols = 3
n_rows = (len(numeric_cols) + n_cols - 1) // n_cols

plt.figure(figsize=(n_cols * 3.5, n_rows * 3))

for i, col in enumerate(numeric_cols, 1):
    plt.subplot(n_rows, n_cols, i)
    data = transportation[col].dropna()
    sns.histplot(data, kde=True, color='skyblue', bins=30)

    dist_name = best_fit_distribution(data)
    plt.title(f"{col} ({dist_name})", fontsize=10)
    plt.xlabel("")
    plt.ylabel("")
    plt.grid(True)

plt.tight_layout()
plt.show()

x= transportation.drop(columns="has_delay", axis=1)
y= transportation["has_delay"]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42 )

smote = SMOTE(sampling_strategy=0.95, k_neighbors=5, random_state=42)
x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)

print("Class distribution before SMOTE:\n", y_train.value_counts(), "\n")
print("Class distribution after SMOTE:\n", y_train_resampled.value_counts())

# Apply normalisation
scaler=MinMaxScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Train and evaluate KNN without PCA**
clf_knn = KNeighborsClassifier(n_neighbors=9)
# Training the model
clf_knn.fit(x_train_scaled, y_train)
# Predict the model
y_pred = clf_knn.predict(x_test_scaled)
# Compute the accuracy
knn_acc = accuracy_score(y_test, y_pred)
print("KNeighbors accuracy score (without PCA):", knn_acc)
# Train and evaluate KNN with PCA**
pca = PCA(n_components=8)
x_train_pca = pca.fit_transform(x_train_scaled)
x_test_pca = pca.transform(x_test_scaled)  # Transform test set separately
# Training the model
clf_knn_pca = KNeighborsClassifier(n_neighbors=9)
clf_knn_pca.fit(x_train_pca, y_train)
# Predict the model
y_pred_pca = clf_knn_pca.predict(x_test_pca)
knn_acc_pca = accuracy_score(y_test, y_pred_pca)
print("KNeighbors accuracy score (with PCA):", knn_acc_pca)

# Lists to store predictions and true labels from all folds
all_preds = []
all_labels = []

# 1. Scale the entire dataset using Min-Max normalization
scaler = MinMaxScaler()
x_scaled = scaler.fit_transform(x)
y = y.reset_index(drop=True)

# 2. Set up K-Fold Cross Validation
kf = KFold(n_splits=4, shuffle=True, random_state=42)
cv_scores = []

# 3. Loop through each fold
for fold, (train_index, val_index) in enumerate(kf.split(x_scaled), 1):
    x_train_fold, x_val_fold = x_scaled[train_index], x_scaled[val_index]
    y_train_fold, y_val_fold = y[train_index], y[val_index]

    # Initialize and train KNN model
    knn = KNeighborsClassifier(n_neighbors=9)
    knn.fit(x_train_fold, y_train_fold)
    # Predict and evaluate each fold
    y_pred = knn.predict(x_val_fold)

    all_preds.extend(y_pred)
    all_labels.extend(y_val_fold)

    acc = accuracy_score(y_val_fold, y_pred)
    cv_scores.append(acc)
    print(f"Fold {fold} Accuracy: {acc:.4f}\n")

# 4. Final average
mean_accuracy = np.mean(cv_scores)
print(f"Mean K-Fold CV Accuracy: {mean_accuracy:.4f}\n")

# 5. Classification report
print("Overall Classification Report:")
print(classification_report(all_labels, all_preds, digits=4))

# 6. Confusion matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix (All Folds Combined)')
plt.show()



from sklearn.metrics import precision_score, recall_score, f1_score
precision = precision_score(all_labels, all_preds, average='weighted')
recall = recall_score(all_labels, all_preds, average='weighted')
f1 = f1_score(all_labels, all_preds, average='weighted')
print(f"Overall Precision: {precision:.4f}")
print(f"Overall Recall:    {recall:.4f}")
print(f"Overall F1-Score:  {f1:.4f}")

from sklearn.metrics import mean_absolute_error, mean_squared_error
# Mean Square Error (MSE)
mse = mean_squared_error(all_labels, all_preds)
print('MSE: ', mse)

from sklearn.ensemble import RandomForestRegressor  # or RandomForestClassifier for classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np

# Example: Assuming you already have your features and target
# X = your features (2D array or DataFrame)
# y = your target values (1D array or Series)

# Split the data into train and test sets (optional but recommended)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Create the Random Forest model
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
model.fit(x_train, y_train)

# Predict on test data
y_pred = model.predict(x_test)

# Evaluate using MSE and RMSE
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print("MSE:", mse)
print("RMSE:", rmse)

# 6. Confusion matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix (All Folds Combined)')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Example: Assuming you already have X and y
# X = your feature matrix
# y = your target labels

# Split the data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Train the classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(x_train, y_train)

# Predict
y_pred = model.predict(x_test)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

from sklearn.metrics import mean_squared_error
import numpy as np

# Predict on test data
y_pred = model.predict(x_test)

# Calculate MSE and RMSE
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

# Assume you already have X and y
# And your model is trained, e.g.:
# model = RandomForestClassifier(...)
# model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(x_test)

# Binary or Multiclass? You can compute metrics like this:
precision = precision_score(y_test, y_pred, average='weighted')  # or 'macro', 'micro', 'binary'
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

from sklearn.metrics import accuracy_score

# Predict on test data
y_pred = model.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)